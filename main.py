from flask import Flask, request, jsonify
from flask_cors import CORS
import openai
import os
import json
import traceback
from ocr import extract_text_with_mathpix

app = Flask(__name__)
CORS(app)

openai.api_key = os.environ.get("OPENAI_API_KEY")

@app.route("/")
def index():
    return "âœ… AI Gaokao Reading System is running."

@app.route("/api/analyze", methods=["POST"])
def analyze():
    try:
        question = request.form.get("question", "").strip()
        history_raw = request.form.get("history", "[]")
        history = json.loads(history_raw)
        file = request.files.get("file")

        if not question:
            return jsonify({"error": "Missing question"}), 400

        # ğŸ§  Step 1: Persistent system prompt
        messages = [{
            "role": "system",
            "content": (
                "ä½ æ˜¯ä¸€ä½ä¸“é—¨æŒ‡å¯¼é«˜è€ƒè‹±è¯­é˜…è¯»ç†è§£çš„AIè€å¸ˆã€‚"
                "è¯·ç”¨ä¸­æ–‡è§£ç­”å­¦ç”Ÿçš„é—®é¢˜ï¼Œé€»è¾‘æ¸…æ™°ï¼Œè¯­è¨€é€šä¿—æ˜“æ‡‚ï¼Œå¼•ç”¨åŸæ–‡æ”¯æŒä½ çš„è§‚ç‚¹ã€‚"
                "å¦‚æœå­¦ç”Ÿæåˆ°æŸä¸ªé¢˜å·ï¼ˆä¾‹å¦‚ Question 22ï¼‰ï¼Œè¯·åœ¨ä¸Šä¸‹æ–‡ä¸­æŸ¥æ‰¾ç›¸å…³å†…å®¹ï¼Œ"
                "å¹¶è¯¦ç»†è§£é‡Šä¸ºä»€ä¹ˆé€‰æ‹©è¯¥ç­”æ¡ˆã€‚"
            )
        }]

        # ğŸ“„ Step 2: Handle new upload
        if file:
            print("ğŸ“¥ New PDF received.")
            extracted_text = extract_text_with_mathpix(file)

            if not extracted_text:
                return jsonify({"answer": "âš ï¸ OCR æ— æ³•è¯†åˆ«ä»»ä½•æ–‡å­—ï¼Œè¯·ä¸Šä¼ æ¸…æ™°çš„ PDF æ–‡ä»¶ã€‚"})

            content_message = f"ä»¥ä¸‹æ˜¯è€ƒç”Ÿä¸Šä¼ çš„PDFå†…å®¹æ‘˜å½•ï¼š\n{extracted_text}"
            messages.append({"role": "user", "content": content_message})

        else:
            print("ğŸ” Follow-up question received.")
            for h in history:
                messages.append({
                    "role": "user" if "å­¦ç”Ÿ" in h["sender"] else "assistant",
                    "content": h["message"]
                })

        # â• Step 3: Add current question
        messages.append({"role": "user", "content": question})

        print("ğŸ§  GPT Message Flow:", messages[-3:])

        response = openai.ChatCompletion.create(
            model="gpt-4",
            messages=messages,
            temperature=0.3,
            max_tokens=600
        )

        answer = response["choices"][0]["message"]["content"].strip()
        if not answer:
            answer = "âš ï¸ AI æ²¡æœ‰è¿”å›ç­”æ¡ˆã€‚è¯·å°è¯•æ›´æ¢é—®é¢˜æˆ–ä¸Šä¼ æ›´æ¸…æ™°çš„ PDFã€‚"

        print("âœ… AI Answer:", answer[:200])
        return jsonify({"answer": answer})

    except Exception as e:
        print("âŒ Backend error:", traceback.format_exc())
        return jsonify({"error": str(e)}), 500

if __name__ == "__main__":
    app.run(debug=True)
