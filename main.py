from flask import Flask, request, jsonify
import openai
import requests
import os
import base64
import fitz  # PyMuPDF
from io import BytesIO
import traceback

app = Flask(__name__)

# âœ… Environment Variables from Vercel
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")
MATHPIX_APP_ID = os.environ.get("MATHPIX_APP_ID")
MATHPIX_APP_KEY = os.environ.get("MATHPIX_APP_KEY")

openai.api_key = OPENAI_API_KEY

def extract_text_with_mathpix(pdf_file):
    extracted_text = ""

    # Open PDF with PyMuPDF
    doc = fitz.open(stream=pdf_file.read(), filetype="pdf")

    # Read up to 3 pages
    for i, page in enumerate(doc.pages(0, min(3, doc.page_count))):
        pix = page.get_pixmap(dpi=200)
        img_bytes = pix.tobytes("png")
        img_b64 = base64.b64encode(img_bytes).decode()

        headers = {
            "app_id": MATHPIX_APP_ID,
            "app_key": MATHPIX_APP_KEY,
            "Content-type": "application/json"
        }

        data = {
            "src": f"data:image/png;base64,{img_b64}",
            "formats": ["text"],
            "ocr": ["math", "text"]
        }

        response = requests.post("https://api.mathpix.com/v3/text", json=data, headers=headers)

        if response.status_code == 200:
            result = response.json()
            page_text = result.get("text", "")
            print(f"ğŸ“„ OCR Page {i+1}:", page_text[:200])
            extracted_text += page_text + "\n"
        else:
            print(f"âŒ MathPix OCR error (page {i+1}):", response.text)

    return extracted_text.strip()

@app.route("/api/analyze", methods=["POST"])
def analyze():
    try:
        if "file" not in request.files or "question" not in request.form:
            return jsonify({"error": "Missing file or question"}), 400

        file = request.files["file"]
        question = request.form["question"]

        # ğŸ” Extract text from PDF
        extracted_text = extract_text_with_mathpix(file)

        if not extracted_text:
            return jsonify({"answer": "âš ï¸ OCR æ— æ³•è¯†åˆ«ä»»ä½•æ–‡å­—ï¼Œè¯·ä¸Šä¼ æ¸…æ™°çš„ PDF æ–‡ä»¶ã€‚"})

        # ğŸ“ GPT prompt
        prompt = f"""
ä½ æ˜¯ä¸€ä½ä¸“é—¨å¸®åŠ©é«˜è€ƒå­¦ç”Ÿç†è§£é˜…è¯»ç†è§£æ–‡ç« å’Œè€ƒè¯•é¢˜ç›®çš„AIè€å¸ˆã€‚

ä»¥ä¸‹æ˜¯ä»å­¦ç”Ÿä¸Šä¼ çš„PDFä¸­æå–çš„å†…å®¹ï¼ˆéƒ¨åˆ†èŠ‚é€‰ï¼‰ï¼š

----------------
{extracted_text}
----------------

å­¦ç”Ÿçš„é—®é¢˜å¦‚ä¸‹ï¼š
{question}

è¯·ç”¨ä¸­æ–‡è¯¦ç»†åœ°è§£é‡Šè¿™ä¸ªé—®é¢˜çš„ç­”æ¡ˆï¼ŒåŒ…æ‹¬ï¼š
- ä½ å¦‚ä½•ç†è§£è¿™ä¸ªé—®é¢˜
- å¦‚ä½•åœ¨æ–‡ç« ä¸­æ‰¾åˆ°ç­”æ¡ˆçº¿ç´¢
- å¯¹åº”çš„æ®µè½å†…å®¹
- æ¨ç†è¿‡ç¨‹
- ä¸ºä»€ä¹ˆè¿™ä¸ªç­”æ¡ˆæ˜¯æ­£ç¡®çš„

è¯·ç¡®ä¿è¯­è¨€æ¸…æ™°ã€é€»è¾‘å®Œæ•´ï¼Œé€‚åˆé«˜ä¸­ç”Ÿç†è§£ã€‚
"""

        print("ğŸ“ Prompt to OpenAI:", prompt[:500])

        ai_response = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,
            max_tokens=500
        )

        answer = ai_response["choices"][0]["message"]["content"].strip()
        if not answer:
            answer = "âš ï¸ AI æ²¡æœ‰è¿”å›ç­”æ¡ˆã€‚è¯·å°è¯•æ›´æ¢é—®é¢˜æˆ–ä¸Šä¼ æ›´æ¸…æ™°çš„ PDFã€‚"

        print("âœ… AI Answer:", answer[:300])
        return jsonify({"answer": answer})

    except Exception as e:
        print("âŒ Backend error:", traceback.format_exc())
        return jsonify({"error": str(e)}), 500

@app.route("/", methods=["GET"])
def home():
    return jsonify({"message": "âœ… Gaokao AI Backend is live."})
